---
title: 'LocalScraper'
description: 'AI-powered extraction from local HTML content'
icon: 'file-code'
---

<Frame>
  <img src="/services/images/localscraper-banner.png" alt="LocalScraper Service" />
</Frame>

## Overview

LocalScraper brings the same powerful AI extraction capabilities as SmartScraper but works with your local HTML content. This makes it perfect for scenarios where you already have the HTML content or need to process cached pages, internal documents, or dynamically generated content.

<Note>
Try LocalScraper instantly in our [interactive playground](https://dashboard.scrapegraphai.com/) - no coding required!
</Note>

## Key Features

<CardGroup cols={2}>
  <Card title="Local Processing" icon="laptop-code">
    Process HTML content directly without making external requests
  </Card>
  <Card title="AI Understanding" icon="brain">
    Same powerful AI extraction as SmartScraper
  </Card>
  <Card title="Faster Processing" icon="bolt">
    No network latency or website loading delays
  </Card>
  <Card title="Full Control" icon="sliders">
    Complete control over your HTML input and processing
  </Card>
</CardGroup>

## Use Cases

### Internal Systems
- Process internally cached pages
- Extract from intranet content
- Handle dynamic JavaScript renders
- Process email templates

### Batch Processing
- Archive data extraction
- Historical content analysis
- Bulk document processing
- Offline content processing

### Development & Testing
- Test extraction logic locally
- Debug content processing
- Prototype without API calls
- Validate schemas offline

<Note>
Want to learn more about our AI-powered scraping technology? Visit our [main website](https://scrapegraphai.com) to discover how we're revolutionizing web data extraction.
</Note>

## Getting Started

### Quick Start

```python
from scrapegraph_py import Client

client = Client(api_key="your-api-key")

html_content = """
<html>
    <body>
        <h1>ScrapeGraphAI</h1>
        <div class="description">
            <p>AI-powered web scraping for modern applications.</p>
        </div>
        <div class="features">
            <ul>
                <li>Smart Extraction</li>
                <li>Local Processing</li>
                <li>Schema Support</li>
            </ul>
        </div>
    </body>
</html>
"""

response = client.localscraper(
    website_html=html_content,
    user_prompt="Extract the company information and features"
)
```

<Note>
Get your API key from the [dashboard](https://dashboard.scrapegraphai.com)
</Note>

<Accordion title="Example Response" icon="terminal">
```json
{
  "request_id": "sg-req-xyz789",
  "status": "completed",
  "user_prompt": "Extract the company information and features",
  "result": {
    "company_name": "ScrapeGraphAI",
    "description": "AI-powered web scraping for modern applications.",
    "features": [
      "Smart Extraction",
      "Local Processing",
      "Schema Support"
    ]
  },
  "error": ""
}
```

The response includes:
- `request_id`: Unique identifier for tracking your request
- `status`: Current status of the extraction
- `result`: The extracted data in structured JSON format
- `error`: Error message (if any occurred during extraction)
</Accordion>

## Advanced Usage

### Custom Schema Example

Define exactly what data you want to extract:

<CodeGroup>

```python Python
from pydantic import BaseModel, Field
from typing import List

class ProductData(BaseModel):
    name: str = Field(description="Product name")
    price: str = Field(description="Product price")
    description: str = Field(description="Product description")
    specifications: List[str] = Field(description="Product specifications")

response = client.localscraper(
    website_html=html_content,
    user_prompt="Extract the product information",
    output_schema=ProductData
)
```

```typescript TypeScript
import { z } from 'zod';

const ProductSchema = z.object({
  name: z.string().describe('Product name'),
  price: z.string().describe('Product price'),
  description: z.string().describe('Product description'),
  specifications: z.array(z.string()).describe('Product specifications')
});

const response = await localScraper(
  apiKey,
  html_content,
  'Extract the product information',
  ProductSchema
);
```

</CodeGroup>

### Async Support

For applications requiring asynchronous execution, LocalScraper provides async support through the `AsyncClient`:

```python
from scrapegraph_py import AsyncClient
import asyncio

async def main():
    html_content = """
    <html>
        <body>
            <h1>Product: Gaming Laptop</h1>
            <div class="price">$999.99</div>
            <div class="description">
                High-performance gaming laptop with RTX 3080.
            </div>
        </body>
    </html>
    """
    
    async with AsyncClient(api_key="your-api-key") as client:
        response = await client.localscraper(
            website_html=html_content,
            user_prompt="Extract the product information"
        )
        print(response)

# Run the async function
asyncio.run(main())
```

## Integration Options

### Official SDKs
- [Python SDK](/sdks/python) - Perfect for data science and backend applications
- [JavaScript SDK](/sdks/javascript) - Ideal for web applications and Node.js

### AI Framework Integrations
- [LangChain Integration](/integrations/langchain) - Use LocalScraper in your LLM workflows
- [LlamaIndex Integration](/integrations/llamaindex) - Build powerful search and QA systems

## Best Practices

### HTML Preparation
1. Ensure HTML is well-formed
2. Include relevant content only
3. Clean up unnecessary markup
4. Handle character encoding properly

### Optimization Tips
- Remove unnecessary scripts and styles
- Clean up dynamic content placeholders
- Preserve important semantic structure
- Include relevant metadata

## Example Projects

Check out our [cookbook](/cookbook/introduction) for real-world examples:
- Dynamic content extraction
- Email template processing
- Cached content analysis
- Batch HTML processing

## API Reference

For detailed API documentation, see:
- [Start Scraping Job](/api-reference/endpoint/localscraper/start)
- [Get Job Status](/api-reference/endpoint/localscraper/get-status)

## Support & Resources

<CardGroup cols={2}>
  <Card title="Documentation" icon="book" href="/introduction">
    Comprehensive guides and tutorials
  </Card>
  <Card title="API Reference" icon="code" href="/api-reference/introduction">
    Detailed API documentation
  </Card>
  <Card title="Community" icon="discord" href="https://discord.gg/uJN7TYcpNa">
    Join our Discord community
  </Card>
  <Card title="GitHub" icon="github" href="https://github.com/ScrapeGraphAI">
    Check out our open-source projects
  </Card>
  <Card title="Main Website" icon="globe" href="https://www.scrapegraphai.com">
    Visit our official website
  </Card>
</CardGroup>

<Card title="Ready to Start?" icon="rocket" href="https://dashboard.scrapegraphai.com">
  Sign up now and get your API key to begin processing your HTML content with LocalScraper!
</Card>
